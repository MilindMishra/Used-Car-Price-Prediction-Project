{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8abc715",
   "metadata": {},
   "source": [
    "# Used Car Price Prediction Project Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99219b8",
   "metadata": {},
   "source": [
    "# `Data Collection Sources:`\n",
    "\n",
    "> - Cars 24 website - https://www.cars24.com/\n",
    "> - Car Dekho website - https://www.cardekho.com/\n",
    "> - Ola Cars website - https://www.ola.cars/\n",
    "> - Olx website - https://www.olx.in/\n",
    "\n",
    "I'll be scraping data for all major cities in India from basically these four websites (after double-checking the legality). Once I have the desired data, I will export it and store it in CSV format, which I will use to develop our **Used Car Price Prediction Project** using Microsoft Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b053cd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the required libraries and dependencies are being imported now.\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time, sys\n",
    "import tqdm.notebook as tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import selenium\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from urllib.parse import urljoin\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as ec\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98e82f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigned URL into varibales\n",
    "url1 = \"https://www.cars24.com/\"\n",
    "url2 = \"https://www.cardekho.com/\"\n",
    "url3 = \"https://www.ola.cars/\"\n",
    "url4 = \"https://www.olx.in/cars_c84\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792125da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response code from Cars 24: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#Data collection from car24\n",
    "page = requests.get(url1)\n",
    "print(\"Legality Response code from Cars 24:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974a5e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('D:/Installed Software  2/chromedriver.exe')\n",
    "driver.get(url1)\n",
    "driver.maximize_window()\n",
    "\n",
    "loc=[\"Delhi\", \"Mumbai\", \"Pune\", \"Bangalore\", \"Hyderabad\", \"Chennai\", \"Kolkata\"]\n",
    "search_btn = driver.find_element_by_xpath(\"//div[@class='_1K8Qe']/button\")\n",
    "search_btn.click()\n",
    "for place in loc:\n",
    "    # select location manually option\n",
    "    #WebDriverWait(driver,10).until(ec.element_to_be_clickable((By.XPATH,'//button[contains(text(),\"SELECT MANUALLY\")]'))).click()\n",
    "   \n",
    "    # search for location\n",
    "    try:\n",
    "        searchbox = driver.find_element_by_xpath('//div[@class=\"_6QaMX\"]/input')\n",
    "        searchbox.send_keys(place)\n",
    "    except NoSuchElementException:\n",
    "        search_btn = driver.find_element_by_xpath(\"//p[@class='_1OR7d']/label\")\n",
    "        search_btn.click()\n",
    "\n",
    "    # confirm click on searched location icon\n",
    "    WebDriverWait(driver,10).until(ec.element_to_be_clickable((By.XPATH,'//ul[@class=\"_16Bvy\"]/li[1]'))).click()\n",
    "\n",
    "    # choose the \"Buy Used Car\" option on the webpage\n",
    "    WebDriverWait(driver,10).until(ec.element_to_be_clickable((By.XPATH,'//a[contains(text(),\"Buy Used Car\")]'))).click()\n",
    "    \n",
    "    scroll_pause_time = 2\n",
    "    screen_height = driver.execute_script(\"return window.screen.height;\")\n",
    "\n",
    "    i = 1\n",
    "    while True:\n",
    "        # scroll one screen height each time\n",
    "        driver.execute_script(\"window.scrollTo(0, {screen_height}*{i});\".format(screen_height=screen_height, i=i))  \n",
    "        i += 1\n",
    "        time.sleep(scroll_pause_time)\n",
    "        # update scroll height each time after scrolled, as the scroll height can change after we scrolled the page\n",
    "        scroll_height = driver.execute_script(\"return document.body.scrollHeight;\")  \n",
    "        # break the loop when the height we need to scroll to is larger than the total scroll height\n",
    "        if (screen_height) * i > scroll_height:\n",
    "            break \n",
    "        \n",
    "    # fetching urls of every used car on the website\n",
    "    urls = []\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='col-4']//a\"):\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    for i in driver.find_elements_by_xpath(\"//div[@class='_1l4fi']//a\"):\n",
    "        urls.append(i.get_attribute(\"href\"))\n",
    "\n",
    "    # obtaining the required data in the empty lists\n",
    "    location = []\n",
    "    year = []\n",
    "    kms_driven = []\n",
    "    car_model = []\n",
    "    owners = []\n",
    "    transmission = []\n",
    "    fuel_type = []\n",
    "    price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3813fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "        \n",
    "    # fetching manufacturing year of used cars\n",
    "    try:\n",
    "        year_tag = driver.find_element_by_xpath(\"//strong[@class='category']//span\")\n",
    "        year.append(year_tag.)\n",
    "    except NoSuchElementException:\n",
    "        year.append('None')\n",
    "        \n",
    "    # fetching number of kms driven of used cars\n",
    "    try:\n",
    "        kms_tag = driver.find_element_by_xpath(\"//div[@class='keyword']//span\")\n",
    "        kms_driven.append(kms_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        kms_driven.append('None')\n",
    "        \n",
    "    # fetching model name of used cars\n",
    "    try:\n",
    "        model_tag = driver.find_element_by_xpath(\"//a[@class='_1UhVsV']//span\")\n",
    "        car_model.append(model_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        car_model.append('None')\n",
    "        \n",
    "        \n",
    "    # fetching transmission details of used cars\n",
    "    try:\n",
    "        transmission_tag = driver.find_element_by_xpath(\"//h2[@class='yhB1nd']//span\")\n",
    "        transmission.append(transmission_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        transmission.append('None')\n",
    "        \n",
    "    # fetching fuel type of used cars\n",
    "    try:\n",
    "        fule_tag = driver.find_element_by_xpath(\"//div[@class='fMghEO']//span\")\n",
    "        fule_type.append(fule_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        fule_type.append('None')\n",
    "        \n",
    "    # fetching price of used cars\n",
    "    try:\n",
    "        price_tag = driver.find_element_by_xpath(\"//p[@class='/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/']//span\")\n",
    "        price.append(price_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dfa16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "cars=pd.DataFrame({'Used Car Model':car_model,\n",
    "                   'Year of Manufacture':year,\n",
    "                   'Kilometer Driven':kms_driven,\n",
    "                   'Fuel Type':fuel_type,\n",
    "                   'Transmission Type':transmission,\n",
    "                   'Used Car Price':price\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29af9bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Car Dekho URL is: <Response [403]>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(url2)\n",
    "print(\"Legality Response number from Car Dekho URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885843f",
   "metadata": {},
   "source": [
    "Since the legality response from the website is not 200 we cannot perform web scraping here and therefore we shall ignore the further process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80d8781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Ola Cars URL is: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(url3)\n",
    "print(\"Legality Response number from Ola Cars URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d1286",
   "metadata": {},
   "source": [
    "Here even though the legality response is 200 we are unable to inspect the webpage as right click is disabled on the website therefore web scraping in such a scenario is not possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc65d44",
   "metadata": {},
   "source": [
    "**Collecting Data from OLX Cars webpage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faba8a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legality Response number from Olx Cars URL is: <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36'}\n",
    "page = requests.get(url4, headers=headers)\n",
    "print(\"Legality Response number from Olx Cars URL is:\", page) # to show the response output from the webpage\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acd007e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome('D:/Installed Software  2/chromedriver.exe')\n",
    "driver.get(url4)\n",
    "driver.maximize_window()\n",
    "\n",
    "# creating empty lists\n",
    "location = []\n",
    "year = []\n",
    "kms_driven = []\n",
    "car_model = []\n",
    "owners = []\n",
    "transmission = []\n",
    "fuel_type = []\n",
    "price = []\n",
    "prod_URL =[]\n",
    "# getting the URL of the cars\n",
    "for i in range(0,500):\n",
    "    url=driver.find_elements_by_xpath(\"//ul[@class='rl3f9 _3mXOU']/li/a\")\n",
    "    for i in url:\n",
    "        prod_URL.append(i.get_attribute('href'))\n",
    "    try:\n",
    "        next_btn=driver.find_element_by_xpath(\"//button[@class='rui-39-wj rui-3evoE rui-1JPTg']\").click()\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    \n",
    "for i in prod_URL:\n",
    "    driver.get(i)  \n",
    "        \n",
    "\n",
    "    #Extracting car name\n",
    "    try:\n",
    "        car_model.append(driver.find_element_by_xpath(\"//div[@class='_3_knn']/div/span[2]\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        car_model.append(\"-\")\n",
    "        \n",
    "    #Extracting the year\n",
    "    try:\n",
    "        year.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_year']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        year.append(\"-\")\n",
    "        \n",
    "    #Extracting the fuel consumed\n",
    "    try:\n",
    "        fuel_type.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_petrol']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        fuel_type.append(\"-\")  \n",
    "        \n",
    "    #Extracting the transmission\n",
    "    try:\n",
    "        transmission.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_transmission']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        transmission.append(\"-\") \n",
    "        \n",
    "    #Extracting km driven\n",
    "    try:\n",
    "        kms_driven.append(driver.find_element_by_xpath(\"//span[@data-aut-id='value_mileage']\").text)\n",
    "    except NoSuchElementException as e:\n",
    "        kms_driven.append(\"-\") \n",
    "        \n",
    "    #Extracting the price details\n",
    "    try:\n",
    "        price.append(driver.find_element_by_xpath(\"//span[@data-aut-id='itemPrice']\").text.replace('₹',''))\n",
    "    except NoSuchElementException as e:\n",
    "        price.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "797084f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe and checking the data extracted\n",
    "cars=pd.DataFrame({'Used Car Model':car_model,\n",
    "                   'Year of Manufacture':year,\n",
    "                   'Kilometer Driven':kms_driven,\n",
    "                   'Fuel Type':fuel_type,\n",
    "                   'Transmission Type':transmission,\n",
    "                   'Used Car Price':price\n",
    "                   })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f4d1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.to_csv(\"Used_Car_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427b2aa2",
   "metadata": {},
   "source": [
    "*Exported the collected used car details from dataframe to csv format to be used for machine learning model building.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce4b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
